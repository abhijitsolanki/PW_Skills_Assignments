{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Of course. Here are the answers to the assignment questions based on the provided document.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Theoretical Questions**\n",
        "\n",
        "#### **1. What is deep learning, and how is it connected to artificial intelligence?**\n",
        "\n",
        "Artificial Intelligence (AI) is a broad field of computer science focused on creating machines capable of intelligent behavior. Machine Learning (ML) is a subset of AI where systems learn from data to make predictions or decisions without being explicitly programmed.\n",
        "\n",
        "Deep Learning (DL) is a further subfield of ML. Its key characteristic is the use of neural networks with many layers (hence \"deep\"). These deep neural networks, known as Deep Neural Networks (DNNs), are inspired by the structure and function of the human brain. They automatically learn hierarchical representations of data, meaning simple features are learned in the initial layers and are combined to form more complex features in deeper layers. This ability to learn features directly from data is what makes deep learning so powerful for tasks like image recognition, natural language processing, and speech recognition.\n",
        "\n",
        "In short, the connection is: AI \\> Machine Learning \\> Deep Learning.\n",
        "\n",
        "#### **2. What is a neural network, and what are the different types of neural networks?**\n",
        "\n",
        "A neural network is a computational model inspired by the biological neural networks that constitute animal brains. It consists of interconnected nodes, called neurons or units, organized in layers. Each connection has an associated weight, which is adjusted during the learning process. The network learns by processing examples, each of which contains a known \"input\" and \"result,\" forming probability-weighted associations between the two.\n",
        "\n",
        "There are several types of neural networks, each suited for different tasks:\n",
        "\n",
        "  * **Feedforward Neural Networks (FNNs):** The simplest type, where information moves in only one direction—from the input layer, through the hidden layers, to the output layer. The Perceptron is the most basic form of an FNN.\n",
        "  * **Convolutional Neural Networks (CNNs):** Primarily used for image processing and computer vision. They use special layers called convolutional layers to automatically and adaptively learn spatial hierarchies of features from images.\n",
        "  * **Recurrent Neural Networks (RNNs):** Designed to work with sequential data, such as time series or text. They have connections that form directed cycles, allowing them to maintain an internal state or \"memory\" of past information.\n",
        "  * **Long Short-Term Memory (LSTM) Networks:** A special kind of RNN that is better at learning long-term dependencies, overcoming some of the limitations of standard RNNs.\n",
        "  * **Transformer Networks:** A more modern architecture that relies on an attention mechanism to handle sequential data. It has become the state-of-the-art for most natural language processing (NLP) tasks.\n",
        "\n",
        "#### **3. What is the mathematical structure of a neural network?**\n",
        "\n",
        "A neural network is a collection of connected neurons organized in layers. The mathematical operation of a single neuron can be described as follows:\n",
        "\n",
        "1.  It receives a set of inputs, $x_1, x_2, ..., x_n$.\n",
        "2.  Each input is multiplied by a corresponding weight, $w_1, w_2, ..., w_n$.\n",
        "3.  The weighted inputs are summed together, and a bias term, $b$, is added. This forms the net input, $z$.\n",
        "    $$z = (w_1x_1 + w_2x_2 + ... + w_nx_n) + b = \\sum_{i=1}^{n} w_i x_i + b$$\n",
        "    In vector notation, this is more cleanly expressed as $z = \\mathbf{w} \\cdot \\mathbf{x} + b$.\n",
        "4.  The net input $z$ is then passed through a non-linear activation function, $f$, to produce the neuron's final output, $y$.\n",
        "    $$y = f(z) = f(\\mathbf{w} \\cdot \\mathbf{x} + b)$$\n",
        "    In a full network, the output of the neurons in one layer becomes the input for the neurons in the next layer. This structure of linear transformations (weighted sum) followed by non-linear activations allows the network to learn and approximate highly complex, non-linear functions.\n",
        "\n",
        "#### **4. What is an activation function, and why is it essential in a neural network?**\n",
        "\n",
        "An activation function is a mathematical function applied to the output of a neuron. It introduces non-linearity into the network.\n",
        "\n",
        "This non-linearity is essential because most real-world data is complex and non-linear. Without activation functions (or with only linear activation functions), a neural network, no matter how many layers it has, would behave just like a single-layer linear model. It would only be able to learn linear relationships. The introduction of non-linearity allows the network to learn complex patterns and approximate any continuous function, which is fundamental to its power.\n",
        "\n",
        "#### **5. Could you list some common activation functions used in neural networks?**\n",
        "\n",
        "Here are some common activation functions:\n",
        "\n",
        "  * **Sigmoid:** It squashes the output to a range between 0 and 1. It's often used in the output layer for binary classification problems.\n",
        "    $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "  * **Hyperbolic Tangent (Tanh):** Similar to sigmoid but squashes the output to a range between -1 and 1.\n",
        "    $$\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$$\n",
        "  * **Rectified Linear Unit (ReLU):** This is the most widely used activation function. It outputs the input directly if it is positive, and zero otherwise. It is computationally efficient and helps mitigate the vanishing gradient problem.\n",
        "    $$\\text{ReLU}(z) = \\max(0, z)$$\n",
        "  * **Leaky ReLU:** A variation of ReLU that allows a small, non-zero gradient when the unit is not active to prevent \"dying ReLU\" problems.\n",
        "    $$\\text{Leaky ReLU}(z) = \\begin{cases} z & \\text{if } z > 0 \\\\ \\alpha z & \\text{otherwise} \\end{cases} \\quad (\\text{where } \\alpha \\text{ is a small constant like 0.01})$$\n",
        "  * **Softmax:** Used in the output layer for multi-class classification problems. It converts a vector of raw scores (logits) into a probability distribution, where the sum of all elements is 1.\n",
        "    $$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } i=1, ..., K$$\n",
        "\n",
        "#### **6. What is a multilayer neural network?**\n",
        "\n",
        "A multilayer neural network, also known as a Multilayer Perceptron (MLP), is a type of feedforward neural network that has at least one hidden layer of neurons between the input and output layers. A simple perceptron has only an input and an output layer and can only learn linearly separable patterns. By adding one or more hidden layers, the network can learn complex, non-linear relationships between the inputs and outputs. Any network with more than one layer (i.e., at least one hidden layer) is considered a \"deep\" network, forming the basis of deep learning.\n",
        "\n",
        "#### **7. What is a loss function, and why is it crucial for neural network training?**\n",
        "\n",
        "A loss function (or cost function) is a method of evaluating how well a specific algorithm models the given data. It quantifies the difference—or \"error\"—between the network's predicted output and the true target value.\n",
        "\n",
        "The loss function is crucial for training because it provides the signal used to update the network's weights. The goal of training is to find a set of weights and biases that minimizes the loss function. The learning process involves calculating the loss for a batch of data, then using an optimization algorithm (like Gradient Descent) to adjust the weights in the direction that reduces the loss. Without a loss function, there would be no way to measure the performance of the network and guide its learning.\n",
        "\n",
        "#### **8. What are some common types of loss functions?**\n",
        "\n",
        "The choice of loss function depends on the type of problem being solved:\n",
        "\n",
        "  * **For Regression Problems (predicting continuous values):**\n",
        "\n",
        "      * **Mean Squared Error (MSE):** Calculates the average of the squares of the differences between the predicted and actual values.\n",
        "        $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "      * **Mean Absolute Error (MAE):** Calculates the average of the absolute differences between the predicted and actual values. It is less sensitive to outliers than MSE.\n",
        "        $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
        "\n",
        "  * **For Classification Problems (predicting a category):**\n",
        "\n",
        "      * **Binary Cross-Entropy:** Used for binary (two-class) classification problems.\n",
        "        $$L = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)]$$\n",
        "      * **Categorical Cross-Entropy:** Used for multi-class classification problems where each sample belongs to exactly one class.\n",
        "        $$L = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{C} y_{ij} \\log(\\hat{y}_{ij})$$\n",
        "\n",
        "#### **9. How does a neural network learn?**\n",
        "\n",
        "A neural network learns through an iterative process called training. The overall process, often involving an algorithm called **backpropagation**, can be summarized in these steps:\n",
        "\n",
        "1.  **Initialization:** The network's weights are initialized with small random values.\n",
        "2.  **Forward Propagation:** A batch of input data is fed into the network. The data passes through the layers, neuron by neuron, and the network produces an output (a prediction).\n",
        "3.  **Loss Calculation:** The predicted output is compared to the true target values using a loss function, which calculates the error or \"loss.\"\n",
        "4.  **Backward Propagation (Backpropagation):** The algorithm calculates the gradient of the loss function with respect to each weight and bias in the network. It does this by propagating the error backward from the output layer to the input layer, using the chain rule of calculus. This gradient indicates the direction in which the weights should be adjusted to reduce the loss.\n",
        "5.  **Weight Update:** An optimizer (e.g., Gradient Descent) updates the weights and biases using the calculated gradients. The update is proportional to a parameter called the **learning rate**.\n",
        "    $$\\text{new\\_weight} = \\text{old\\_weight} - \\text{learning\\_rate} \\times \\text{gradient}$$\n",
        "    These five steps are repeated for many batches of data (epochs) until the loss is minimized and the model's performance on a validation dataset stops improving.\n",
        "\n",
        "#### **10. What is an optimizer in neural networks, and why is it necessary?**\n",
        "\n",
        "An optimizer is an algorithm or method used to change the attributes of the neural network, such as weights and biases, to reduce the loss. Optimizers help to minimize the loss function.\n",
        "\n",
        "They are necessary because the process of finding the optimal set of weights to minimize the loss is a complex optimization problem. The loss function can be visualized as a high-dimensional surface with many hills and valleys. The optimizer's job is to navigate this surface efficiently to find the lowest point (global minimum) or a sufficiently low point (local minimum). Different optimizers use different strategies to perform this navigation, affecting the speed and success of the training process.\n",
        "\n",
        "#### **11. Could you briefly describe some common optimizers?**\n",
        "\n",
        "  * **Stochastic Gradient Descent (SGD):** A fundamental optimizer. It updates the network's weights using the gradient calculated from a single training example or a small batch of examples at a time. This makes it computationally faster and can help escape local minima, but the updates can be noisy.\n",
        "  * **Adam (Adaptive Moment Estimation):** A popular and effective optimizer that adapts the learning rate for each weight. It computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients. It combines the advantages of two other extensions of SGD: AdaGrad and RMSprop.\n",
        "  * **RMSprop (Root Mean Square Propagation):** This optimizer also adapts the learning rate for each weight. It divides the learning rate by an exponentially decaying average of squared gradients. It works well in practice and is a common choice for RNNs.\n",
        "\n",
        "#### **12. Can you explain forward and backward propagation in a neural network?**\n",
        "\n",
        "  * **Forward Propagation:** This is the process of feeding input data through the network to generate an output. The input data enters the input layer and travels through the hidden layers to the output layer. At each neuron, the inputs are multiplied by their corresponding weights, summed up with a bias, and then passed through an activation function. The output of one layer serves as the input to the next. The final result at the output layer is the network's prediction.\n",
        "\n",
        "  * **Backward Propagation (Backpropagation):** This is the core algorithm for training neural networks. After a prediction is made via forward propagation, the loss (error) is calculated. Backpropagation works by propagating this error backward through the network. Using the chain rule from calculus, it calculates the gradient of the loss function with respect to each weight and bias. These gradients measure the contribution of each weight to the overall error. The optimizer then uses these gradients to update the weights in a way that minimizes the error.\n",
        "\n",
        "#### **13. What is weight initialization, and how does it impact training?**\n",
        "\n",
        "Weight initialization is the process of setting the initial values for the weights in a neural network before training begins.\n",
        "\n",
        "It has a significant impact on the training process:\n",
        "\n",
        "  * **Poor Initialization:** If weights are initialized to be too large, it can lead to the **exploding gradient** problem, where the gradients become excessively large and training is unstable. If weights are initialized to be too small or all to zero, it can lead to the **vanishing gradient** problem, where gradients become tiny and the network learns very slowly or not at all. Initializing all weights to zero is problematic because all neurons in a layer will learn the same features.\n",
        "  * **Good Initialization:** Proper initialization helps in faster convergence and increases the likelihood of finding a good solution. It helps prevent the gradient from vanishing or exploding. Common strategies include:\n",
        "      * **Random Initialization:** Initializing weights to small random numbers.\n",
        "      * **Xavier (Glorot) Initialization:** Designed for layers using Sigmoid or Tanh activation functions. It sets the weights from a distribution with a variance that depends on the number of input and output neurons.\n",
        "      * **He Initialization:** Similar to Xavier but adapted for ReLU activation functions, which are now more common.\n",
        "\n",
        "#### **14. What is the vanishing gradient problem in deep learning?**\n",
        "\n",
        "The vanishing gradient problem occurs in deep neural networks, particularly those using activation functions like sigmoid or tanh. During backpropagation, the gradients are calculated by repeatedly multiplying gradients from later layers by gradients from earlier layers (due to the chain rule). If these gradients are small (less than 1), their product shrinks exponentially as it is propagated backward.\n",
        "\n",
        "As a result, the gradients for the weights in the initial layers become extremely small (\"vanish\"). This means the weights of these layers are updated very slowly, if at all. Consequently, the initial layers fail to learn, and the overall network cannot learn complex, long-range dependencies in the data.\n",
        "\n",
        "This problem can be mitigated by using activation functions like ReLU, using smarter weight initialization like He initialization, or using architectures like LSTMs or networks with residual connections (ResNets).\n",
        "\n",
        "#### **15. What is the exploding gradient problem?**\n",
        "\n",
        "The exploding gradient problem is the opposite of the vanishing gradient problem. It occurs when the gradients calculated during backpropagation become excessively large. This is often due to weight initializations that are too large or a learning rate that is too high.\n",
        "\n",
        "When gradients explode, the weight updates are also very large, causing the network's weights to oscillate wildly and become unstable. The loss may become `NaN` (Not a Number), and the training process fails. This problem can be addressed by:\n",
        "\n",
        "  * **Gradient Clipping:** Capping the gradients at a certain threshold to prevent them from exceeding it.\n",
        "  * **Weight Regularization:** Adding a penalty to the loss function to keep the weights small.\n",
        "  * **Using a smaller learning rate.**\n",
        "\n",
        "-----\n",
        "\n",
        "### **Practical Questions**\n",
        "\n",
        "#### **1. How do you create a simple perceptron for basic binary classification?**\n",
        "\n",
        "Here is a simple implementation of a Perceptron using Python's NumPy library to classify the AND logical gate."
      ],
      "metadata": {
        "id": "Tv7dlLTiUfJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"A simple Perceptron classifier.\"\"\"\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._step_function\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def _step_function(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data.\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "\n",
        "                # Perceptron update rule\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels for samples in X.\"\"\"\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "# Example: AND gate\n",
        "if __name__ == '__main__':\n",
        "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    y = np.array([0, 0, 0, 1])\n",
        "\n",
        "    p = Perceptron(learning_rate=0.1, n_iters=10)\n",
        "    p.fit(X, y)\n",
        "\n",
        "    print(\"Perceptron classification for AND gate:\")\n",
        "    for x_input in X:\n",
        "        prediction = p.predict(x_input)\n",
        "        print(f\"Input: {x_input}, Predicted: {prediction}\")\n",
        "\n",
        "    print(f\"\\nLearned Weights: {p.weights}\")\n",
        "    print(f\"Learned Bias: {p.bias}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron classification for AND gate:\n",
            "Input: [0 0], Predicted: 0\n",
            "Input: [0 1], Predicted: 0\n",
            "Input: [1 0], Predicted: 0\n",
            "Input: [1 1], Predicted: 1\n",
            "\n",
            "Learned Weights: [0.2 0.1]\n",
            "Learned Bias: -0.20000000000000004\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTFeGdu1UfJY",
        "outputId": "87321718-c7a9-4e15-e800-1096fce8eef1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. How can you build a neural network with one hidden layer using Keras?**\n",
        "\n",
        "You can use the `Sequential` model in Keras to stack layers. Here's how to build a simple network with one hidden layer."
      ],
      "metadata": {
        "id": "Sh0ZN3cBUfJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential([\n",
        "    # Input layer (implicitly defined by input_shape in the first layer)\n",
        "    # The hidden layer with 64 neurons and ReLU activation\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "\n",
        "    # The output layer with 10 neurons (for 10 classes) and softmax activation\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "mWhX8VkMUfJa",
        "outputId": "b46443ac-d796-45e5-c081-d865c7c1153c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. How do you initialize weights using the Xavier (Glorot) initialization method in Keras?**\n",
        "\n",
        "You can specify the weight initializer using the `kernel_initializer` argument in a layer. Keras uses `'glorot_uniform'` (Xavier uniform) by default for `Dense` layers, but you can specify it explicitly."
      ],
      "metadata": {
        "id": "Esu0-4MWUfJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(\n",
        "        64,\n",
        "        activation='tanh', # Tanh is often used with Glorot initialization\n",
        "        input_shape=(100,),\n",
        "        kernel_initializer='glorot_uniform' # Xavier uniform initialization\n",
        "    ),\n",
        "    layers.Dense(\n",
        "        10,\n",
        "        activation='softmax',\n",
        "        kernel_initializer='glorot_normal' # Xavier normal initialization\n",
        "    )\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,114\u001b[0m (27.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,114</span> (27.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,114\u001b[0m (27.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,114</span> (27.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "nsnnARnfUfJb",
        "outputId": "e56a9328-048a-459c-b999-3606a36118f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. How can you apply different activation functions in a neural network in Keras?**\n",
        "\n",
        "You can set the `activation` parameter for each `Dense` layer to a different function."
      ],
      "metadata": {
        "id": "aMSh887EUfJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Hidden Layer 1: ReLU activation\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "\n",
        "    # Hidden Layer 2: Tanh activation\n",
        "    layers.Dense(64, activation='tanh'),\n",
        "\n",
        "    # Output Layer: Sigmoid activation for binary classification\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m108,801\u001b[0m (425.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,801</span> (425.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m108,801\u001b[0m (425.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,801</span> (425.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "m3P8OJOWUfJd",
        "outputId": "9c040906-986f-4287-b7e3-a8a0c4c0cf58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. How do you add dropout to a neural network model to prevent overfitting?**\n",
        "\n",
        "Dropout is a regularization technique where randomly selected neurons are ignored during training. You can add it as a `Dropout` layer in Keras."
      ],
      "metadata": {
        "id": "8AdEICeLUfJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    # Add a dropout layer with a 50% rate\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    # Add another dropout layer with a 25% rate\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "dlFIP0IIUfJf",
        "outputId": "7114a2d4-247c-4959-d93a-9f63cb955d7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6. How do you manually implement forward propagation in a simple neural network?**\n",
        "\n",
        "Here is a manual implementation of forward propagation using NumPy for a network with one hidden layer."
      ],
      "metadata": {
        "id": "id9FKlM0UfJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward_prop(X, weights1, bias1, weights2, bias2):\n",
        "    \"\"\"\n",
        "    Manual forward propagation for a 1-hidden-layer network.\n",
        "\n",
        "    Args:\n",
        "    - X: Input data (n_samples, n_features)\n",
        "    - weights1, bias1: Parameters for the hidden layer\n",
        "    - weights2, bias2: Parameters for the output layer\n",
        "    \"\"\"\n",
        "    # Calculate hidden layer output\n",
        "    Z1 = np.dot(X, weights1) + bias1\n",
        "    A1 = sigmoid(Z1) # Activation of hidden layer\n",
        "\n",
        "    # Calculate output layer output\n",
        "    Z2 = np.dot(A1, weights2) + bias2\n",
        "    A2 = sigmoid(Z2) # Final prediction\n",
        "\n",
        "    return A2\n",
        "\n",
        "# Example usage\n",
        "# Network with 2 input neurons, 3 hidden neurons, 1 output neuron\n",
        "n_input = 2\n",
        "n_hidden = 3\n",
        "n_output = 1\n",
        "\n",
        "# Dummy input data (1 sample)\n",
        "X_sample = np.array([[0.5, 0.2]])\n",
        "\n",
        "# Randomly initialized weights and biases\n",
        "W1 = np.random.randn(n_input, n_hidden)\n",
        "b1 = np.zeros((1, n_hidden))\n",
        "W2 = np.random.randn(n_hidden, n_output)\n",
        "b2 = np.zeros((1, n_output))\n",
        "\n",
        "prediction = forward_prop(X_sample, W1, b1, W2, b2)\n",
        "print(f\"Input: {X_sample}\")\n",
        "print(f\"Predicted Output: {prediction}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [[0.5 0.2]]\n",
            "Predicted Output: [[0.72775777]]\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-pC5qhYUfJg",
        "outputId": "a3590962-4eae-4d8e-8f80-917abcf5fa8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **7. How do you add batch normalization to a neural network model in Keras?**\n",
        "\n",
        "Batch Normalization is a technique to stabilize and accelerate training. You can add it using the `BatchNormalization` layer, typically between a linear layer (`Dense`) and its activation function."
      ],
      "metadata": {
        "id": "7eEl80z0UfJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, input_shape=(784,)),\n",
        "    # Add batch normalization before the activation\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "\n",
        "    layers.Dense(64),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,154\u001b[0m (430.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,154</span> (430.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,770\u001b[0m (428.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,770</span> (428.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "gmpV5bOTUfJh",
        "outputId": "71496de7-7716-405d-e77c-45d3e8566128"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **8. How can you visualize the training process with accuracy and loss curves?**\n",
        "\n",
        "The `model.fit()` method in Keras returns a `History` object. You can use this object with `matplotlib` to plot the training and validation loss and accuracy over epochs."
      ],
      "metadata": {
        "id": "56WqV_UYUfJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create dummy data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "\n",
        "# 2. Build the model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the model and store the history\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=10,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# 5. Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8399 - loss: 0.5662 - val_accuracy: 0.9512 - val_loss: 0.1759\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1607 - val_accuracy: 0.9616 - val_loss: 0.1317\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.1103 - val_accuracy: 0.9654 - val_loss: 0.1126\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0757 - val_accuracy: 0.9719 - val_loss: 0.0991\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0630 - val_accuracy: 0.9690 - val_loss: 0.0972\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0476 - val_accuracy: 0.9739 - val_loss: 0.0874\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0399 - val_accuracy: 0.9756 - val_loss: 0.0849\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0298 - val_accuracy: 0.9747 - val_loss: 0.0820\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0262 - val_accuracy: 0.9735 - val_loss: 0.0886\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.9766 - val_loss: 0.0833\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "UNC09tSkUfJh",
        "outputId": "ed747af8-e47b-4fd0-b3db-eacc43f6e200"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **9. How can you use gradient clipping in Keras to control the gradient size and prevent exploding gradients?**\n",
        "\n",
        "You can set the `clipnorm` or `clipvalue` arguments when you instantiate an optimizer.\n",
        "\n",
        "  * `clipvalue`: Clips gradients to be within the range `[-value, value]`.\n",
        "  * `clipnorm`: Clips gradients when their L2 norm exceeds the specified value.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "6RRCFOhHUfJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Using clipvalue\n",
        "optimizer_cv = keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.0)\n",
        "\n",
        "# Using clipnorm\n",
        "optimizer_cn = keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.0)\n",
        "\n",
        "# Then compile your model with the chosen optimizer\n",
        "# model.compile(optimizer=optimizer_cv, loss='...')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "id": "z1yXW40MUfJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **10. How can you create a custom loss function in Keras?**\n",
        "\n",
        "You can define a Python function that takes `y_true` (true labels) and `y_pred` (predictions) as arguments. This function should use TensorFlow/Keras backend functions to compute the loss."
      ],
      "metadata": {
        "id": "IBZ12MMSUfJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define a custom loss function (e.g., Mean Absolute Percentage Error)\n",
        "def custom_huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) <= delta\n",
        "    squared_loss = 0.5 * tf.square(error)\n",
        "    linear_loss  = delta * (tf.abs(error) - 0.5 * delta)\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "# Dummy data for a regression problem\n",
        "X_train = np.random.rand(100, 10)\n",
        "y_train = np.random.rand(100, 1)\n",
        "\n",
        "# Build model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(32, activation='relu', input_shape=(10,)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model with the custom loss function\n",
        "model.compile(optimizer='adam', loss=custom_huber_loss)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0796  \n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0769 \n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0701 \n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0711 \n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7869e829ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InmcZoWTUfJi",
        "outputId": "4c9c6780-e489-435c-cc2e-6d161c4f57fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **11. How can you visualize the structure of a neural network model in Keras?**\n",
        "\n",
        "Keras provides two main ways to inspect a model's architecture:\n",
        "\n",
        "1.  **`model.summary()`**: Prints a text-based summary of the model, including layers, output shapes, and the number of parameters.\n",
        "2.  **`keras.utils.plot_model()`**: Generates an image file that visually represents the model graph. This requires the `pydot` and `graphviz` libraries to be installed.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "B7z-xMPhUfJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Build a model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,), name='input_layer'),\n",
        "    layers.Dropout(0.2, name='dropout_1'),\n",
        "    layers.Dense(64, activation='relu', name='hidden_layer_1'),\n",
        "    layers.Dense(10, activation='softmax', name='output_layer')\n",
        "])\n",
        "\n",
        "# 1. Print the text summary\n",
        "print(\"--- Model Summary ---\")\n",
        "model.summary()\n",
        "\n",
        "# 2. Plot the model to a file\n",
        "# Make sure you have pydot and graphviz installed:\n",
        "# pip install pydot graphviz\n",
        "try:\n",
        "    keras.utils.plot_model(\n",
        "        model,\n",
        "        to_file='model_plot.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True,\n",
        "        show_layer_activations=True\n",
        "    )\n",
        "    print(\"\\nModel plot saved to model_plot.png\")\n",
        "except ImportError:\n",
        "    print(\"\\nPlease install pydot and graphviz to plot the model.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Summary ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model plot saved to model_plot.png\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "wb7Fv2ieUfJi",
        "outputId": "7eb9c4e3-d9eb-4739-b6e7-c2c8c0e9fea7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}